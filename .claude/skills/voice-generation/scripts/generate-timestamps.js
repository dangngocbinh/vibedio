const fs = require('fs-extra');
const path = require('path');
const dotenv = require('dotenv');
const minimist = require('minimist');
const { OpenAI } = require('openai');
const { execSync } = require('child_process');

// NOTE FOR VUE DEVELOPER:
// Load environment variables t·ª´ th∆∞ m·ª•c g·ªëc project
// T∆∞∆°ng t·ª± nh∆∞ import.meta.env trong Vue/Vite, nh∆∞ng ·ªü Node.js d√πng dotenv
// __dirname = /Users/binhpc/code/automation-video/.claude/skills/voice-generation/scripts
// ƒêi l√™n 4 c·∫•p ƒë·ªÉ ƒë·∫øn /Users/binhpc/code/automation-video/
dotenv.config({ path: path.join(__dirname, '../../../../.env') });

// Parse command-line arguments
// NOTE FOR VUE DEVELOPER:
// minimist library parse CLI arguments th√†nh object
// T∆∞∆°ng t·ª± nh∆∞ props trong Vue component
// Example: --audio "file.mp3" --text "hello" ‚Üí ARGS = { audio: "file.mp3", text: "hello" }
const ARGS = minimist(process.argv.slice(2));

// Configuration
const CONFIG = {
    openaiApiKey: process.env.OPENAI_API_KEY,
};

/**
 * Get actual audio duration using ffprobe
 * NOTE FOR VUE DEVELOPER:
 * execSync l√† c√°ch ch·∫°y shell command trong Node.js, t∆∞∆°ng t·ª± nh∆∞ child_process trong browser
 * ffprobe l√† tool ƒë·ªÉ ƒë·ªçc metadata t·ª´ audio/video files
 * 
 * @param {string} audioPath - Path to audio file
 * @returns {number} Duration in seconds, or null if failed
 */
function getAudioDuration(audioPath) {
    try {
        // Ch·∫°y ffprobe command ƒë·ªÉ l·∫•y duration
        // -v error: ch·ªâ hi·ªán errors
        // -show_entries format=duration: ch·ªâ hi·ªán duration
        // -of default=noprint_wrappers=1:nokey=1: format output ƒë∆°n gi·∫£n
        const result = execSync(
            `ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 "${audioPath}"`,
            { encoding: 'utf8', timeout: 10000 }
        );
        const duration = parseFloat(result.trim());
        if (!isNaN(duration)) {
            return Math.round(duration * 100) / 100; // Round to 2 decimal places
        }
    } catch (err) {
        console.warn(`Warning: Could not get audio duration via ffprobe: ${err.message}`);
    }
    return null;
}

/**
 * Generate Word-level Timestamps using OpenAI Whisper
 * NOTE FOR VUE DEVELOPER:
 * async/await trong Node.js gi·ªëng h·ªát trong Vue
 * OpenAI SDK s·ª≠ d·ª•ng pattern t∆∞∆°ng t·ª± nh∆∞ axios trong Vue
 * 
 * @param {string} audioPath - Path to audio file
 * @param {string} originalText - Optional original text for prompt (improves accuracy)
 * @returns {Array} Array of {word, start, end} objects
 */
async function generateTimestampsWithWhisper(audioPath, originalText = null) {
    if (!CONFIG.openaiApiKey) {
        throw new Error('Missing OPENAI_API_KEY in .env file. Please add it to generate timestamps.');
    }

    const openai = new OpenAI({ apiKey: CONFIG.openaiApiKey });

    // Create read stream from audio file
    // NOTE FOR VUE DEVELOPER:
    // fs.createReadStream t·∫°o stream ƒë·ªÉ ƒë·ªçc file l·ªõn m√† kh√¥ng load to√†n b·ªô v√†o RAM
    // T∆∞∆°ng t·ª± nh∆∞ streaming trong HTTP requests
    const audioStream = fs.createReadStream(audioPath);

    console.log('üì° Calling OpenAI Whisper API for transcription...');

    try {
        // NOTE FOR VUE DEVELOPER:
        // API call n√†y t∆∞∆°ng t·ª± nh∆∞ axios.post() trong Vue
        // response_format: "verbose_json" ƒë·ªÉ l·∫•y th√™m metadata
        // timestamp_granularities: ["word"] ƒë·ªÉ l·∫•y timestamps ·ªü m·ª©c t·ª´ng t·ª´ (word-level)
        const response = await openai.audio.transcriptions.create({
            file: audioStream,
            model: "whisper-1",
            response_format: "verbose_json",
            timestamp_granularities: ["word"],
            // N·∫øu c√≥ originalText, pass v√†o prompt ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c
            ...(originalText && { prompt: originalText })
        });

        // Extract word-level timestamps
        // NOTE FOR VUE DEVELOPER:
        // .map() trong JavaScript gi·ªëng h·ªát .map() trong Vue/Array methods
        // Transform array t·ª´ format c·ªßa Whisper sang format c·ªßa ch√∫ng ta
        if (response.words) {
            console.log(`‚úÖ Generated ${response.words.length} word timestamps`);
            return response.words.map(w => ({
                word: w.word,
                start: w.start,
                end: w.end
            }));
        }

        console.warn('‚ö†Ô∏è  No word timestamps returned from Whisper API');
        return null;
    } catch (error) {
        console.error('‚ùå Whisper API Error:', error.message);
        throw error;
    }
}

/**
 * Main function
 */
async function main() {
    try {
        // Validate arguments
        // NOTE FOR VUE DEVELOPER:
        // Validation n√†y gi·ªëng nh∆∞ computed properties ho·∫∑c form validation trong Vue
        const audioPath = ARGS.audio;
        const originalText = ARGS.text || null;
        const outputDir = ARGS.outputDir || null;

        if (!audioPath) {
            console.error('‚ùå Error: --audio argument is required');
            console.log('\nUsage:');
            console.log('  node generate-timestamps.js --audio "path/to/voice.mp3" [options]');
            console.log('\nOptions:');
            console.log('  --audio         Path to audio file (required)');
            console.log('  --text          Original text for better accuracy (optional)');
            console.log('  --outputDir     Custom output directory (optional, default: same as audio file)');
            console.log('\nExample:');
            console.log('  node .claude/skills/voice-generation/scripts/generate-timestamps.js \\');
            console.log('    --audio "public/projects/my-video/voice.mp3" \\');
            console.log('    --text "Xin ch√†o c√°c b·∫°n"');
            process.exit(1);
        }

        // Resolve absolute path
        // NOTE FOR VUE DEVELOPER:
        // path.resolve() t∆∞∆°ng t·ª± nh∆∞ path normalization
        // Chuy·ªÉn relative path th√†nh absolute path ƒë·ªÉ tr√°nh l·ªói
        const absoluteAudioPath = path.isAbsolute(audioPath)
            ? audioPath
            : path.join(process.cwd(), audioPath);

        // Check if audio file exists
        if (!await fs.pathExists(absoluteAudioPath)) {
            console.error(`‚ùå Error: Audio file not found: ${absoluteAudioPath}`);
            process.exit(1);
        }

        console.log('\nüéµ Generating timestamps for existing voice file...');
        console.log(`üìÅ Audio file: ${absoluteAudioPath}`);
        if (originalText) {
            console.log(`üìù Original text: "${originalText.substring(0, 50)}${originalText.length > 50 ? '...' : ''}"`);
        }

        // Get audio duration
        const duration = getAudioDuration(absoluteAudioPath);
        if (duration) {
            console.log(`‚è±Ô∏è  Audio duration: ${duration}s`);
        }

        // Generate timestamps via Whisper
        const timestamps = await generateTimestampsWithWhisper(absoluteAudioPath, originalText);

        if (!timestamps || timestamps.length === 0) {
            console.error('‚ùå Failed to generate timestamps');
            process.exit(1);
        }

        // Determine output location
        // NOTE FOR VUE DEVELOPER:
        // Logic n√†y t∆∞∆°ng t·ª± nh∆∞ computed property trong Vue
        // N·∫øu c√≥ outputDir th√¨ d√πng, kh√¥ng th√¨ d√πng c√πng th∆∞ m·ª•c v·ªõi audio file
        let jsonPath;
        if (outputDir) {
            await fs.ensureDir(outputDir);
            const audioFilename = path.basename(absoluteAudioPath);
            const baseFilename = path.basename(audioFilename, path.extname(audioFilename));
            jsonPath = path.join(outputDir, `${baseFilename}.json`);
        } else {
            // Save in same directory as audio file
            const audioDir = path.dirname(absoluteAudioPath);
            const audioFilename = path.basename(absoluteAudioPath);
            const baseFilename = path.basename(audioFilename, path.extname(audioFilename));
            jsonPath = path.join(audioDir, `${baseFilename}.json`);
        }

        // Calculate duration from timestamps (more accurate)
        const durationFromTimestamps = timestamps.length > 0
            ? timestamps[timestamps.length - 1].end
            : duration;

        // Create metadata object
        // NOTE FOR VUE DEVELOPER:
        // Object n√†y t∆∞∆°ng t·ª± nh∆∞ data object trong Vue component
        // Ch·ª©a t·∫•t c·∫£ metadata c·∫ßn thi·∫øt cho video editor
        const metadata = {
            text: originalText || '(transcribed from audio)',
            provider: 'external', // Voice t·ª´ ngu·ªìn b√™n ngo√†i
            audioFile: path.basename(absoluteAudioPath),
            duration: duration,
            durationFromTimestamps: durationFromTimestamps,
            timestamps: timestamps,
            timestamp_source: 'whisper',
            generatedAt: new Date().toISOString()
        };

        // Save metadata to JSON file
        await fs.writeJson(jsonPath, metadata, { spaces: 2 });

        console.log('\n‚úÖ Success!');
        console.log(`üìÑ Metadata saved to: ${jsonPath}`);
        console.log(`üìä Generated ${timestamps.length} word timestamps`);
        if (durationFromTimestamps) {
            console.log(`‚è±Ô∏è  Total duration: ${durationFromTimestamps}s`);
        }

    } catch (error) {
        console.error('\n‚ùå Generation Failed:', error.message);
        if (error.response) {
            console.error('API Error Status:', error.response.status);
            try {
                console.error('API Error Data:', JSON.stringify(error.response.data, null, 2));
            } catch (e) {
                console.error('API Error Data:', error.response.data);
            }
        }
        process.exit(1);
    }
}

// Run main function
// NOTE FOR VUE DEVELOPER:
// Trong Node.js, code ch·∫°y ngay khi file ƒë∆∞·ª£c execute
// Kh√¥ng gi·ªëng Vue component c·∫ßn mount v√†o DOM
main();
